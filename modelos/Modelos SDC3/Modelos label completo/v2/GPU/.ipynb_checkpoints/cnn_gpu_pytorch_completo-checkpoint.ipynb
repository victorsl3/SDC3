{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/21953404Victor/SDC3/tutorial-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import optuna\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos a partir de los archivos FITS\n",
    "path_datos = \"/home/21953404Victor/SDC3/SDC3GIT/data_actualizada/\"\n",
    "path_repo=\"/home/21953404Victor/SDC3/SDC3GIT/\"\n",
    "path = path_datos + \"ZW3.msw_image.fits\"\n",
    "hdul = fits.open(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación del catálogo de fuentes completo (almacenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ruta_carpeta_catalogos = \"/home/21953404Victor/SDC3/SDC3GIT/catalogos/catalogo completo 2/resultados/resultados_detection4\"\n",
    "# ruta_carpeta_resultados = \"/home/21953404Victor/SDC3/SDC3GIT/catalogos/catalogo completo 2/labels\"\n",
    "# archivos = os.listdir(ruta_carpeta_catalogos)\n",
    "\n",
    "# # Función para crear un archivo de anotación para cada catálogo\n",
    "# def crear_anotaciones(path_cat, path_anotacion):\n",
    "#     cat = Table.read(path_cat, format=\"ascii\")\n",
    "#     clase = \"fuente\"\n",
    "\n",
    "#     with open(path_anotacion, \"w\") as f:\n",
    "#         for row in cat:\n",
    "#             x = row[\"X_IMAGE\"]\n",
    "#             y = row[\"Y_IMAGE\"]\n",
    "#             f.write(f\"{x} {y} {clase}\\n\")\n",
    "\n",
    "# # Procesar todos los archivos de catálogo en la carpeta\n",
    "# for archivo in archivos:\n",
    "#     # Extraer el número de kHz del nombre del archivo\n",
    "#     num_khz = re.search(r\"(\\d+)kHz\", archivo).group(1)\n",
    "\n",
    "#     # Crear un nombre para el archivo de anotación correspondiente\n",
    "#     anotacion_nombre = f\"catalogo_completo_1_{num_khz}kHz.txt\"\n",
    "\n",
    "#     # Crear el archivo de anotación para el catálogo actual\n",
    "#     crear_anotaciones(\n",
    "#         os.path.join(ruta_carpeta_catalogos, archivo),\n",
    "#         os.path.join(ruta_carpeta_resultados, anotacion_nombre)\n",
    "#    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta_carpeta_resultados = \"/home/21953404Victor/SDC3/SDC3GIT/catalogos/catalogo completo 1/labels\"\n",
    "# archivos = os.listdir(ruta_carpeta_resultados)\n",
    "\n",
    "# def clamp(value, min_value, max_value):\n",
    "#     return max(min(value, max_value), min_value)\n",
    "\n",
    "# def procesar_archivo(path_txt):\n",
    "#     with open(path_txt, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#     label = np.zeros((2048, 2048), dtype=int)\n",
    "\n",
    "#     for line in lines:\n",
    "#         x, y, _ = line.split()\n",
    "#         x, y = int(float(x)), int(float(y))\n",
    "\n",
    "#         for i in range(-4, 4):\n",
    "#             for j in range(-4, 4):\n",
    "#                 x_coord = clamp(x + i, 0, 2047)\n",
    "#                 y_coord = clamp(y + j, 0, 2047)\n",
    "#                 label[y_coord, x_coord] = 1\n",
    "\n",
    "#     return label\n",
    "\n",
    "# # Crear una lista para guardar los datos procesados\n",
    "# target=[]\n",
    "\n",
    "# # Procesar todos los archivos de texto en la carpeta de resultados\n",
    "# for archivo in archivos:\n",
    "#     path_txt = os.path.join(ruta_carpeta_resultados, archivo)\n",
    "#     label = procesar_archivo(path_txt)\n",
    "#     target.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Configurar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos y dividirlos en conjuntos de entrenamiento y validación\n",
    "num_samples = len(hdul[0].data) # Cargar todos los datos en lugar de una muestra de todas las imágenes\n",
    "all_data = hdul[0].data\n",
    "indices = sorted(np.random.choice(all_data.shape[0], num_samples, replace=False))\n",
    "data = all_data[indices]\n",
    "\n",
    "input_data = np.array(data).astype(\"float32\") / 255.0 # Normalizar los datos de entrada (en formato de 8 bits implica que cad píxel tenga un valor de 0 a 255)\n",
    "input_data = input_data.reshape((data.shape[0], 1, data.shape[1], data.shape[2]))\n",
    "\n",
    "del all_data\n",
    "del hdul\n",
    "del data\n",
    "\n",
    "# En lugar de repetir el label ahora se carga la lista de labels. El resto del proceso es igual\n",
    "output_data = np.array(fits.open(path_repo+'catalogos/catalogo completo 2/fit/LABEL_COMPLETO_V2.fit')[0].data).astype(\"float32\")#[:, np.newaxis, :, :] # Agregar una dimensión para mantener el formato de los datos de entrada de la red neuronal\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "\n",
    "del input_data\n",
    "del output_data\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train).unsqueeze(1)\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(dropout_rate, out_channels1, out_channels2, out_channels3):\n",
    "    decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(out_channels3, out_channels2, 3, stride=2, padding=1, output_padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(out_channels2),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.ConvTranspose2d(out_channels2, out_channels1, 3, stride=2, padding=1, output_padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(out_channels1),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.ConvTranspose2d(out_channels1, 1, 3, padding=1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    return decoder.to(device)\n",
    "\n",
    "def create_encoder(input_channels, num_filters1, num_filters2, dropout_rate, out_channels3):\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Conv2d(input_channels, num_filters1, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters1),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Conv2d(num_filters1, num_filters2, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_filters2),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Conv2d(num_filters2, out_channels3, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_rate)\n",
    "    )\n",
    "    return encoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Cargar y dividir tus datos en conjuntos de entrenamiento y validación\n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    val_data = TensorDataset(x_val, y_val)    \n",
    "    \n",
    "    # Crear DataLoaders para entrenamiento y validación\n",
    "    tam_lote = 1\n",
    "    train_loader = DataLoader(train_data, batch_size=tam_lote, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=tam_lote, shuffle=False)\n",
    "\n",
    "    # Hiperparámetros sugeridos por Optuna\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.0, 0.5)\n",
    "    \n",
    "    # Aquí también sugerimos el número de canales en las capas de convolución del decoder\n",
    "    out_channels1 = trial.suggest_int(\"out_channels1\", 16, 64)\n",
    "    out_channels2 = trial.suggest_int(\"out_channels2\", 16, 64)\n",
    "    out_channels3 = trial.suggest_int(\"out_channels3\", 16, 64)\n",
    "    \n",
    "    # Sugerir el número de filtros en las capas de convolución del encoder\n",
    "    num_filters1 = trial.suggest_int(\"num_filters1\", 16, 64)\n",
    "\n",
    "    num_filters2 = trial.suggest_int(\"num_filters2\", 16, 64)\n",
    "\n",
    "    # Imprimir los hiperparámetros utilizados en este trial\n",
    "    print(f\"Hiperparámetros del trial {trial.number}:\")\n",
    "    print(f\"lr: {lr}, dropout_rate: {dropout_rate}\")\n",
    "    print(f\"out_channels1: {out_channels1}, out_channels2: {out_channels2}, out_channels3: {out_channels3}\")\n",
    "    print(f\"num_filters1: {num_filters1}, num_filters2: {num_filters2}\")\n",
    "\n",
    "    # Crear el modelo de 'encoder' y 'decoder' con los hiperparámetros sugeridos\n",
    "    input_channels = 1\n",
    "    encoder = create_encoder(input_channels, num_filters1, num_filters2, dropout_rate, out_channels3)\n",
    "    decoder = create_decoder(dropout_rate, out_channels1, out_channels2, out_channels3)\n",
    "\n",
    "    # Función de pérdida y optimizador\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "\n",
    "    # Crear un directorio para guardar los modelos intermedios, si aún no existe\n",
    "    os.makedirs(\"modelos_intermedios\", exist_ok=True)\n",
    "\n",
    "    # Entrenamiento y validación del modelo\n",
    "    num_epochs = 50\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            #train\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                enc_output = encoder(images)\n",
    "                dec_output = decoder(enc_output)\n",
    "\n",
    "                # Convertir las etiquetas a float\n",
    "                labels_float = labels.float()\n",
    "\n",
    "                loss = criterion(dec_output, labels_float)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "            \n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            #test\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "                    enc_output = encoder(images)\n",
    "                    dec_output = decoder(enc_output)\n",
    "                    dec_output = torch.squeeze(dec_output, dim=1) \n",
    "                    \n",
    "                    # Convertir las etiquetas a float\n",
    "                    labels_float = labels.float()\n",
    "                    labels_float = torch.squeeze(labels_float, dim=1)\n",
    "                    \n",
    "                    loss = criterion(dec_output, labels_float)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Pérdida del train: {train_losses[-1]}, Pérdida del test: {val_losses[-1]}\")\n",
    "\n",
    "        # Guardar los modelos intermedios\n",
    "        trial_number = trial.number\n",
    "        decoder_path = f\"modelos_intermedios/decoder_gpu_cat_completo_trial_{trial_number}.pt\"\n",
    "        encoder_path = f\"modelos_intermedios/encoder_gpu_cat_completo_trial_{trial_number}.pt\"\n",
    "        \n",
    "        torch.save(decoder.state_dict(), decoder_path)\n",
    "        torch.save(encoder.state_dict(), encoder_path)\n",
    "\n",
    "        # Limpiar la GPU\n",
    "        del decoder\n",
    "        del encoder\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Guardar el plot de pérdidas por epoch\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"modelos_intermedios/loss_plot_trial_{trial_number}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        return val_losses[-1]  # Devolver la pérdida de validación del último epoch\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\"[W] El trial {trial.number} falló debido a un error de falta de memoria en la GPU\")\n",
    "            print(\"Continuando con la optimización de parámetros, ignorando esta última configuración\")\n",
    "            \n",
    "            # Limpiar la GPU\n",
    "            del decoder\n",
    "            del encoder\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Asignar un valor alto para que este trial no sea seleccionado como el mejor\n",
    "            return float(\"inf\")\n",
    "        else:\n",
    "            # Vuelve a generar la excepción si el error no es \"CUDA out of memory\"\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-22 22:20:25,647]\u001b[0m A new study created in memory with name: no-name-9ba02462-e132-4131-a9ad-064f3b699b95\u001b[0m\n",
      "/tmp/ipykernel_65891/1417001533.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_65891/1417001533.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.0, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros del trial 0:\n",
      "lr: 8.376955816897811e-05, dropout_rate: 0.47220170652264104\n",
      "out_channels1: 45, out_channels2: 16, out_channels3: 19\n",
      "num_filters1: 51, num_filters2: 30\n",
      "Epoch 1/50, Pérdida del train: 0.4696391566346089, Pérdida del test: 2.703907136759047\n",
      "Epoch 2/50, Pérdida del train: 0.14701624592352244, Pérdida del test: 28.721445378677622\n",
      "Epoch 3/50, Pérdida del train: 0.08914602258139187, Pérdida del test: 49.473499761760564\n",
      "Epoch 4/50, Pérdida del train: 0.07260030157243212, Pérdida del test: 0.9132511174481218\n"
     ]
    }
   ],
   "source": [
    "# Crear un estudio de optimización\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Ejecutar el estudio de optimización con la función 'objective' y un número determinado de ensayos\n",
    "study.optimize(objective, n_trials=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('study.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(\"Tasa de aprendizaje:\", study.best_params[\"lr\"])\n",
    "print(\"Tasa de dropout:\", study.best_params[\"dropout_rate\"])\n",
    "print(\"Número de filtros en la primera capa convolucional del encoder:\", study.best_params[\"num_filters1\"])\n",
    "print(\"Número de filtros en la segunda capa convolucional del encoder:\", study.best_params[\"num_filters2\"])\n",
    "print(\"Número de canales en la primera capa del decoder:\", study.best_params[\"out_channels1\"])\n",
    "print(\"Número de canales en la segunda capa del decoder:\", study.best_params[\"out_channels2\"])\n",
    "print(\"Número de canales en la tercera capa del decoder:\", study.best_params[\"out_channels3\"])\n",
    "\n",
    "# Obtener el número del mejor ensayo\n",
    "best_trial_number = study.best_trial.number\n",
    "\n",
    "# Crear un nuevo 'decoder' y 'encoder' con los mejores hiperparámetros encontrados\n",
    "decoder = create_decoder(\n",
    "    study.best_params[\"dropout_rate\"],\n",
    "    study.best_params[\"out_channels1\"],\n",
    "    study.best_params[\"out_channels2\"],\n",
    "    study.best_params[\"out_channels3\"])\n",
    "\n",
    "encoder = create_encoder(\n",
    "    1, # número de canales de entrada\n",
    "    study.best_params[\"num_filters1\"],\n",
    "    study.best_params[\"num_filters2\"],\n",
    "    study.best_params[\"dropout_rate\"],\n",
    "    study.best_params[\"out_channels3\"]\n",
    ")\n",
    "\n",
    "# Cargar los estados de los mejores modelos\n",
    "decoder_path = f\"modelos_intermedios/decoder_gpu_cat_completo_trial_{best_trial_number}.pt\"\n",
    "encoder_path = f\"modelos_intermedios/encoder_gpu_cat_completo_trial_{best_trial_number}.pt\"\n",
    "\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "encoder.load_state_dict(torch.load(encoder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "Tasa de aprendizaje: 1.1794071655396725e-05\n",
      "Tasa de dropout: 0.18154908905670702\n",
      "Número de filtros en la primera capa convolucional del encoder: 27\n",
      "Número de filtros en la segunda capa convolucional del encoder: 44\n",
      "Número de canales en la primera capa del decoder: 16\n",
      "Número de canales en la segunda capa del decoder: 32\n",
      "Número de canales en la tercera capa del decoder: 46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(\"Tasa de aprendizaje:\", study.best_params[\"lr\"])\n",
    "print(\"Tasa de dropout:\", study.best_params[\"dropout_rate\"])\n",
    "print(\"Número de filtros en la primera capa convolucional del encoder:\", study.best_params[\"num_filters1\"])\n",
    "print(\"Número de filtros en la segunda capa convolucional del encoder:\", study.best_params[\"num_filters2\"])\n",
    "print(\"Número de canales en la primera capa del decoder:\", study.best_params[\"out_channels1\"])\n",
    "print(\"Número de canales en la segunda capa del decoder:\", study.best_params[\"out_channels2\"])\n",
    "print(\"Número de canales en la tercera capa del decoder:\", study.best_params[\"out_channels3\"])\n",
    "\n",
    "# Obtener el número del mejor ensayo\n",
    "best_trial_number = study.best_trial.number\n",
    "\n",
    "# Crear un nuevo 'decoder' y 'encoder' con los mejores hiperparámetros encontrados\n",
    "decoder = create_decoder(\n",
    "    study.best_params[\"dropout_rate\"],\n",
    "    study.best_params[\"out_channels1\"],\n",
    "    study.best_params[\"out_channels2\"],\n",
    "    study.best_params[\"out_channels3\"])\n",
    "\n",
    "encoder = create_encoder(\n",
    "    1, # número de canales de entrada\n",
    "    study.best_params[\"num_filters1\"],\n",
    "    study.best_params[\"num_filters2\"],\n",
    "    study.best_params[\"dropout_rate\"],\n",
    "    study.best_params[\"out_channels3\"]\n",
    ")\n",
    "\n",
    "# Cargar los estados de los mejores modelos\n",
    "decoder_path = f\"modelos_intermedios/decoder_gpu_cat_completo_trial_{best_trial_number}.pt\"\n",
    "encoder_path = f\"modelos_intermedios/encoder_gpu_cat_completo_trial_{best_trial_number}.pt\"\n",
    "\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-env",
   "language": "python",
   "name": "tutorial-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
