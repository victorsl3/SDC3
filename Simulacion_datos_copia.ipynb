{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOEZU224Fky8"
   },
   "source": [
    "# Simulación de un cubo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkx8jCUVFrAR"
   },
   "source": [
    "# Simulación de imágenes independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgPJIZ13FzfD"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "\n",
    "# Ésta función nos va a dar la intensidad de una fuente simulada a partir de el data_cube inicial,\n",
    "# el valor máximo de las varianzas y el valor máximo de la intensidad de la fuente.\n",
    "\n",
    "\n",
    "def mock_data( data_cube, sigma_max_x, sigma_max_y, Amax ):\n",
    "\n",
    "    # Creamos una matriz M de ceros con el tamaño del cubo de datos:\n",
    "    xmax = np.shape(data_cube)[0]\n",
    "    ymax = np.shape(data_cube)[1]\n",
    "    M = np.zeros((xmax, ymax))\n",
    "    # Generamos aleatoriamente la posición media de la fuente en los ejes x, y dentro de la imagen, así como los valores máximos para la intensidad y las varianzas:\n",
    "    A = np.random.rand()*Amax #Intensidad (almacenarla y que sea siempre mayor al ruido blanco añadido)\n",
    "    sigmax = np.random.rand()*sigma_max_x\n",
    "    sigmay = np.random.rand()*sigma_max_y #anchuras\n",
    "    x_mid = random.randint(0, xmax)\n",
    "    y_mid = random.randint(0, ymax)\n",
    "    label_structure={\"class\":\"galaxy\", \"x\":x_mid, \"y\":y_mid,\"width\":sigmax, \"height\": sigmay}\n",
    "\n",
    "    # Calculamos una distribución gaussiana para la fuente en los 3 ejes:\n",
    "    x = (np.arange(0,xmax)-x_mid)**2./(2.*sigmax**2.)\n",
    "    y = (np.arange(0,ymax)-y_mid)**2./(2.*sigmay**2.)\n",
    "\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    \n",
    "    M = A*np.exp(-X-Y)\n",
    "    \n",
    "    return [M,label_structure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2Kq9qeOGmJ3",
    "outputId": "1cfd37bb-95a2-4e57-fd98-6f6cdcb6ad7c"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "n_images=100\n",
    "for n in range(n_images):\n",
    "  # definimos el tamaño de los ejes del cubo\n",
    "  x_len = 512\n",
    "  y_len = 512\n",
    "\n",
    "  # creamos una matriz de (512,512) de ceros para almacenar los datos\n",
    "  data_cube = np.zeros((x_len, y_len))\n",
    "\n",
    "  # definimos las varianzas y la intensidad máxima de las fuentes.\n",
    "\n",
    "  Amax = 1\n",
    "  sigma_max_x = 10 \n",
    "  sigma_max_y= 10  \n",
    "\n",
    "  # Añadimos un ruido blanco a la imagen en todas las frecuencias\n",
    "  Noise = np.reshape(np.random.normal(0, Amax/50, x_len*y_len), (x_len, y_len)) # Por qué justo entre 50?\n",
    "  data_cube_noise = data_cube + Noise\n",
    "\n",
    "  # Creamos N fuentes con esas características.\n",
    "\n",
    "  N = 100 #El número de galaxias\n",
    "\n",
    "  fuentes=[] #Almacenamos las fuentes para el label\n",
    "  ax=[]\n",
    "\n",
    "  boxes=[]\n",
    "\n",
    "  for i in range(N):\n",
    "      mock=mock_data(data_cube_noise, sigma_max_x, sigma_max_y, Amax)\n",
    "      boxes.append(mock[1])\n",
    "      data_cube_noise = data_cube_noise + mock[0]\n",
    "\n",
    "  data.append([data_cube_noise, boxes])\n",
    "  print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Y3eidHvegIp"
   },
   "outputs": [],
   "source": [
    "#Creamos una lista para almacenar los arrays binarios\n",
    "binaries=[]\n",
    "\n",
    "#Creamos una lista para almacenar los arrays de etiquetas\n",
    "labels=[]\n",
    "\n",
    "for k in range(len(data)):\n",
    "  #Definimos el tamaño de la imagen\n",
    "  x_len = 512\n",
    "  y_len = 512\n",
    "  #Inicializamos los arrays binarios\n",
    "  binary=np.zeros((x_len, y_len))\n",
    "  #Recorremos los boxes\n",
    "  for box in data[k][1]:\n",
    "    #Definimos los límites de la caja\n",
    "    x_min=int(box['x']-box['width'])\n",
    "    x_max=int(box['x']+box['width'])\n",
    "    y_min=int(box['y']-box['height'])\n",
    "    y_max=int(box['y']+box['height'])\n",
    "    #Rellenamos los límites con etiquetas\n",
    "    binary[x_min:x_max, y_min:y_max] = 1\n",
    "  #Almacenamos los arrays binarios\n",
    "  binaries.append(binary)\n",
    "  #Añadimos las etiquetas\n",
    "  labels.append(data[k][1])\n",
    "\n",
    "#Creamos una lista con todos los datos\n",
    "data_total=[binaries, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6771x52QP4YY",
    "outputId": "8420a0cf-0e5f-4f5d-a5d8-569143ecc0ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the array\n",
    "print('Array:\\n', data)\n",
    "file = open(\"galaxies.txt\", \"w+\")\n",
    " \n",
    "# Saving the array in a text file\n",
    "content = str(data)\n",
    "file.write(content)\n",
    "file.close()\n",
    " \n",
    "# Displaying the contents of the text file\n",
    "file = open(\"galaxies.txt\", \"r\")\n",
    "content = file.read()\n",
    " \n",
    "print(\"\\nContent in galaxies.txt:\\n\", content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdamiOVkH4rL"
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "hdulist = fits.HDUList() #instancia HDUList\n",
    "\n",
    "for n in data:\n",
    "  data_cube_noise=n[0]\n",
    "  from astropy.io import fits\n",
    "  hdulist.append(fits.PrimaryHDU(data_cube_noise.T))# agregamos nuestro cubo de datos\n",
    "  \n",
    "#Guardamos el cubo\n",
    "try:\n",
    "  hdulist.writeto('data_imagen_simulada.fits')\n",
    "except Exception as e:\n",
    "  import os\n",
    "  os.remove('data_imagen_simulada.fits')\n",
    "  hdulist.writeto('data_imagen_simulada.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_wna4XzIwot",
    "outputId": "92ca15ec-5821-45d1-be93-dd544c8940d2"
   },
   "outputs": [],
   "source": [
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "VFDCLameJDQb",
    "outputId": "3da1eb6a-d375-4c97-fa2f-da0dc51482b1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(hdulist[0].data, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qb1rVPPewv0"
   },
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrLZBHtNeyho"
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "label=[]\n",
    "for n in range (n_images):\n",
    "  images.append(hdulist[n].data)\n",
    "  label.append(data_total[0][n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWyhan4LhRn_"
   },
   "outputs": [],
   "source": [
    "#Como cada imagen es una nueva simulación no necesitamos aleatorizar los datos\n",
    "\n",
    "# Definir tamaño de los conjuntos de entrenamiento y prueba \n",
    "train_size = int(0.7 * len(images))\n",
    "test_size = len(images) - train_size\n",
    "\n",
    "# Separar los conjuntos de entrenamiento y prueba \n",
    "train_images = images[:train_size]\n",
    "train_label = label[:train_size]\n",
    "test_images = images[train_size:]\n",
    "test_label = label[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8jAH8LMqYvR",
    "outputId": "a08a2658-679e-4567-e5a0-b3a7ad1b5410"
   },
   "outputs": [],
   "source": [
    "np.shape(train_images)\n",
    "np.shape(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKXa0XbFetRu"
   },
   "outputs": [],
   "source": [
    "#Importar las librerías necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "\n",
    "#Definir modelo\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#Agregar capas\n",
    "model.add(Input(shape=(512, 512, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Compilar modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenar modelo\n",
    "model.fit(x=train_images, \n",
    "          y=train_label, \n",
    "          epochs=10, \n",
    "          validation_data=(test_images, test_label))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
